{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8870083,"sourceType":"datasetVersion","datasetId":5338273}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nimport xgboost as xgb\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\n\nimport re\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom gensim.models import Word2Vec, Doc2Vec\nfrom gensim.models.doc2vec import TaggedDocument\nfrom transformers import BertTokenizer, BertModel\nfrom nltk.stem import WordNetLemmatizer, PorterStemmer\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-31T16:38:21.898444Z","iopub.execute_input":"2024-10-31T16:38:21.899055Z","iopub.status.idle":"2024-10-31T16:38:21.908349Z","shell.execute_reply.started":"2024-10-31T16:38:21.899010Z","shell.execute_reply":"2024-10-31T16:38:21.906592Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:38:21.910786Z","iopub.execute_input":"2024-10-31T16:38:21.911179Z","iopub.status.idle":"2024-10-31T16:41:49.423794Z","shell.execute_reply.started":"2024-10-31T16:38:21.911144Z","shell.execute_reply":"2024-10-31T16:41:49.421530Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\nreplace /usr/share/nltk_data/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\")\ndf.drop(['Unnamed: 0'], axis=1, inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:41:49.428087Z","iopub.execute_input":"2024-10-31T16:41:49.428779Z","iopub.status.idle":"2024-10-31T16:41:50.179943Z","shell.execute_reply.started":"2024-10-31T16:41:49.428719Z","shell.execute_reply":"2024-10-31T16:41:50.178454Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                           statement   status\n0                                         oh my gosh  Anxiety\n1  trouble sleeping, confused mind, restless hear...  Anxiety\n2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n3  I've shifted my focus to something else but I'...  Anxiety\n4  I'm restless and restless, it's been a month n...  Anxiety","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>statement</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>oh my gosh</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>trouble sleeping, confused mind, restless hear...</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I've shifted my focus to something else but I'...</td>\n      <td>Anxiety</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm restless and restless, it's been a month n...</td>\n      <td>Anxiety</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['statement'] = df['statement'].fillna('')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:41:50.181532Z","iopub.execute_input":"2024-10-31T16:41:50.181883Z","iopub.status.idle":"2024-10-31T16:41:50.201334Z","shell.execute_reply.started":"2024-10-31T16:41:50.181849Z","shell.execute_reply":"2024-10-31T16:41:50.200142Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    \n    text = re.sub(r'http\\S+|www\\S+', '', text)\n    text = re.sub(r'\\S+@\\S+', '', text)\n    text = re.sub(r'<.*?>', '', text)\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\d+', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text\n\ndf['statement'] = df['statement'].apply(clean_text)\n\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:41:50.205444Z","iopub.execute_input":"2024-10-31T16:41:50.205945Z","iopub.status.idle":"2024-10-31T16:41:56.133102Z","shell.execute_reply.started":"2024-10-31T16:41:50.205900Z","shell.execute_reply":"2024-10-31T16:41:56.131670Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                               statement      status\n36177  rt floweryhillside i donât want them to come f...    Suicidal\n19558  i worked alone office of one for years it ate ...  Depression\n1489                                      i love you mom      Normal\n19679  okay so since i was young i love coffee i howe...  Depression\n49603  starting to feel hypomanic i havent felt this ...     Bipolar","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>statement</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36177</th>\n      <td>rt floweryhillside i donât want them to come f...</td>\n      <td>Suicidal</td>\n    </tr>\n    <tr>\n      <th>19558</th>\n      <td>i worked alone office of one for years it ate ...</td>\n      <td>Depression</td>\n    </tr>\n    <tr>\n      <th>1489</th>\n      <td>i love you mom</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>19679</th>\n      <td>okay so since i was young i love coffee i howe...</td>\n      <td>Depression</td>\n    </tr>\n    <tr>\n      <th>49603</th>\n      <td>starting to feel hypomanic i havent felt this ...</td>\n      <td>Bipolar</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\n\ndef remove_stopwords(text):\n    tokens = word_tokenize(text)\n    tokens = [word for word in tokens if word not in stop_words]\n    return ' '.join(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:41:56.134656Z","iopub.execute_input":"2024-10-31T16:41:56.135027Z","iopub.status.idle":"2024-10-31T16:41:56.144076Z","shell.execute_reply.started":"2024-10-31T16:41:56.134982Z","shell.execute_reply":"2024-10-31T16:41:56.142456Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df['statement'] = df['statement'].apply(lambda x: remove_stopwords(x))\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:41:56.146068Z","iopub.execute_input":"2024-10-31T16:41:56.146490Z","iopub.status.idle":"2024-10-31T16:42:23.149365Z","shell.execute_reply.started":"2024-10-31T16:41:56.146444Z","shell.execute_reply":"2024-10-31T16:42:23.148070Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                                               statement      status\n38096  never really experience sadness depressed thought  Depression\n32794                         latest fire killed someone      Normal\n26301  hi everyone sorry put much baggage shoulders n...    Suicidal\n42066                          struggling hard inventory      Normal\n38356  exhausted stop sleeping staying awake struggle...  Depression","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>statement</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38096</th>\n      <td>never really experience sadness depressed thought</td>\n      <td>Depression</td>\n    </tr>\n    <tr>\n      <th>32794</th>\n      <td>latest fire killed someone</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>26301</th>\n      <td>hi everyone sorry put much baggage shoulders n...</td>\n      <td>Suicidal</td>\n    </tr>\n    <tr>\n      <th>42066</th>\n      <td>struggling hard inventory</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>38356</th>\n      <td>exhausted stop sleeping staying awake struggle...</td>\n      <td>Depression</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\n\n# Fit and transform the labels in the DataFrame\ndf['status'] = label_encoder.fit_transform(df['status'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:42:23.150971Z","iopub.execute_input":"2024-10-31T16:42:23.151318Z","iopub.status.idle":"2024-10-31T16:42:23.176464Z","shell.execute_reply.started":"2024-10-31T16:42:23.151283Z","shell.execute_reply":"2024-10-31T16:42:23.174822Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                           statement  status\n0                                            oh gosh       0\n1  trouble sleeping confused mind restless heart ...       0\n2  wrong back dear forward doubt stay restless re...       0\n3  ive shifted focus something else im still worried       0\n4                im restless restless month boy mean       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>statement</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>oh gosh</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>trouble sleeping confused mind restless heart ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>wrong back dear forward doubt stay restless re...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ive shifted focus something else im still worried</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>im restless restless month boy mean</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize lemmatizer and stemmer\nlemmatizer = WordNetLemmatizer()\nstemmer = PorterStemmer()\n\n# Function to apply lemmatization\ndef lemmatize_text(text):\n    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n\n# Function to apply stemming\ndef stem_text(text):\n    return ' '.join([stemmer.stem(word) for word in text.split()])\n\n# Function to generate datasets with different vectorization methods\ndef generate_datasets(text_data, vectorization_methods=[\"tfidf\", \"count\", \"word2vec\", \"doc2vec\", \"bert\"]):\n    datasets = {}\n\n    # Prepare different versions of the text data\n    original_data = text_data\n    lemmatized_data = [lemmatize_text(text) for text in text_data]\n    stemmed_data = [stem_text(text) for text in text_data]\n\n    text_variations = {\n        'original': original_data,\n        'lemmatized': lemmatized_data,\n        'stemmed': stemmed_data\n    }\n    \n    # Iterate over each version of text data\n    for version, data in text_variations.items():\n        print(f\"Generating datasets for: {version}...\")  # Progress tracking\n        \n        # TF-IDF Vectorization\n        if \"tfidf\" in vectorization_methods:\n            print(\" - Applying TF-IDF Vectorization...\")\n            tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n            X_tfidf = tfidf_vectorizer.fit_transform(data).toarray()\n            datasets[f'{version}_tfidf'] = X_tfidf\n\n        # Count Vectorization\n        if \"count\" in vectorization_methods:\n            print(\" - Applying Count Vectorization...\")\n            count_vectorizer = CountVectorizer(max_features=5000)\n            X_count = count_vectorizer.fit_transform(data).toarray()\n            datasets[f'{version}_count'] = X_count\n\n        # Word2Vec Embeddings\n        if \"word2vec\" in vectorization_methods:\n            print(\" - Applying Word2Vec Embeddings...\")\n            tokenized_data = [text.split() for text in data]\n            word2vec_model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4)\n            X_word2vec = np.array([\n                np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv] or [np.zeros(100)], axis=0) \n                for words in tokenized_data\n            ])\n            datasets[f'{version}_word2vec'] = X_word2vec\n\n        # Doc2Vec Embeddings\n        if \"doc2vec\" in vectorization_methods:\n            print(\" - Applying Doc2Vec Embeddings...\")\n            tagged_data = [TaggedDocument(words=text.split(), tags=[i]) for i, text in enumerate(data)]\n            doc2vec_model = Doc2Vec(vector_size=100, min_count=1, epochs=20)\n            doc2vec_model.build_vocab(tagged_data)\n            doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n            X_doc2vec = np.array([doc2vec_model.infer_vector(text.split()) for text in data])\n            datasets[f'{version}_doc2vec'] = X_doc2vec\n        \n        print(f\"Completed datasets for: {version}.\\n\")  # Completion notification\n\n    return datasets\n# Function to split datasets into train and test sets\ndef split_datasets(datasets, labels, test_size=0.2, random_state=42):\n    split_datasets = {}\n    \n    for name, X in datasets.items():\n        X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=test_size, random_state=random_state)\n        split_datasets[name] = (X_train, X_test, y_train, y_test)\n        \n    return split_datasets","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:42:23.178140Z","iopub.execute_input":"2024-10-31T16:42:23.178573Z","iopub.status.idle":"2024-10-31T16:42:23.197826Z","shell.execute_reply.started":"2024-10-31T16:42:23.178535Z","shell.execute_reply":"2024-10-31T16:42:23.196122Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"text_data = df['statement']\nlabels = df['status']\n\n# Generate datasets with specified vectorizations and versions\ndatasets = generate_datasets(text_data, vectorization_methods=[\"tfidf\", \"count\", \"word2vec\", \"doc2vec\"])\n\n# Split the datasets into train and test sets\nsplit_datasets = split_datasets(datasets, labels)\n\n# Print shapes of each generated train/test split dataset\nfor name, (X_train, X_test, y_train, y_test) in split_datasets.items():\n    print(f\"{name} - Train shape: {X_train.shape}, Test shape: {X_test.shape}, YTrain shape: {y_train.shape}, YTest shape: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T16:42:23.199505Z","iopub.execute_input":"2024-10-31T16:42:23.199912Z","iopub.status.idle":"2024-10-31T17:00:32.452702Z","shell.execute_reply.started":"2024-10-31T16:42:23.199872Z","shell.execute_reply":"2024-10-31T17:00:32.451232Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Generating datasets for: original...\n - Applying TF-IDF Vectorization...\n - Applying Count Vectorization...\n - Applying Word2Vec Embeddings...\n - Applying Doc2Vec Embeddings...\nCompleted datasets for: original.\n\nGenerating datasets for: lemmatized...\n - Applying TF-IDF Vectorization...\n - Applying Count Vectorization...\n - Applying Word2Vec Embeddings...\n - Applying Doc2Vec Embeddings...\nCompleted datasets for: lemmatized.\n\nGenerating datasets for: stemmed...\n - Applying TF-IDF Vectorization...\n - Applying Count Vectorization...\n - Applying Word2Vec Embeddings...\n - Applying Doc2Vec Embeddings...\nCompleted datasets for: stemmed.\n\noriginal_tfidf - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\noriginal_count - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\noriginal_word2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\noriginal_doc2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\nlemmatized_tfidf - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\nlemmatized_count - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\nlemmatized_word2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\nlemmatized_doc2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\nstemmed_tfidf - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\nstemmed_count - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\nstemmed_word2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\nstemmed_doc2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print shapes of each generated train/test split dataset\nfor name, (X_train, X_test, y_train, y_test) in split_datasets.items():\n    print(f\"{name} - Train shape: {X_train.shape}, Test shape: {X_test.shape}, YTrain shape: {y_train.shape}, YTest shape: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:00:32.455925Z","iopub.execute_input":"2024-10-31T17:00:32.456346Z","iopub.status.idle":"2024-10-31T17:00:32.464095Z","shell.execute_reply.started":"2024-10-31T17:00:32.456311Z","shell.execute_reply":"2024-10-31T17:00:32.462583Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"original_tfidf - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\noriginal_count - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\noriginal_word2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\noriginal_doc2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\nlemmatized_tfidf - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\nlemmatized_count - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\nlemmatized_word2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\nlemmatized_doc2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\nstemmed_tfidf - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\nstemmed_count - Train shape: (42434, 5000), Test shape: (10609, 5000), YTrain shape: (42434,), YTest shape: (10609,)\nstemmed_word2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\nstemmed_doc2vec - Train shape: (42434, 100), Test shape: (10609, 100), YTrain shape: (42434,), YTest shape: (10609,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to compare models (XGBoost and MLP)\ndef compare_models(X_train, X_test, y_train, y_test, label_encoder):\n    # Initialize and fit XGBoost model\n    xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n    xgb_model.fit(X_train, y_train)\n    \n    # Make predictions\n    xgb_pred = xgb_model.predict(X_test)\n\n    # Initialize and fit MLP model\n    mlp_model = MLPClassifier(max_iter=500)\n    mlp_model.fit(X_train, y_train)\n    \n    # Make predictions\n    mlp_pred = mlp_model.predict(X_test)\n\n    # Inverse transform the predictions\n    xgb_pred_classes = label_encoder.inverse_transform(xgb_pred)\n    mlp_pred_classes = label_encoder.inverse_transform(mlp_pred)\n\n    # Generate classification reports\n    xgb_report = classification_report(y_test, xgb_pred, target_names=label_encoder.classes_)\n    mlp_report = classification_report(y_test, mlp_pred, target_names=label_encoder.classes_)\n\n    results = {\n        'XGBoost': {\n            'predictions': xgb_pred_classes,\n            'classification_report': xgb_report\n        },\n        'MLP': {\n            'predictions': mlp_pred_classes,\n            'classification_report': mlp_report\n        }\n    }\n\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:00:32.466474Z","iopub.execute_input":"2024-10-31T17:00:32.467547Z","iopub.status.idle":"2024-10-31T17:00:32.476601Z","shell.execute_reply.started":"2024-10-31T17:00:32.467473Z","shell.execute_reply":"2024-10-31T17:00:32.475331Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Store results for each dataset comparison\ncomparison_results = {}\n\n# Loop through each dataset\nfor name, (X_train, X_test, y_train, y_test) in split_datasets.items():\n    print(f\"Comparing models on dataset: {name}\")\n    results = compare_models(X_train, X_test, y_train, y_test, label_encoder)\n    comparison_results[name] = results\n\n# Print comparison results\nfor dataset_name, result in comparison_results.items():\n    print(f\"\\nResults for {dataset_name}:\")\n    for model_name, metrics in result.items():\n        print(f\"{model_name} Classification Report:\\n{metrics['classification_report']}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:04:02.752010Z","iopub.execute_input":"2024-10-31T17:04:02.753546Z","iopub.status.idle":"2024-10-31T19:22:20.848077Z","shell.execute_reply.started":"2024-10-31T17:04:02.753484Z","shell.execute_reply":"2024-10-31T19:22:20.845354Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Comparing models on dataset: original_tfidf\nComparing models on dataset: original_count\nComparing models on dataset: original_word2vec\nComparing models on dataset: original_doc2vec\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Comparing models on dataset: lemmatized_tfidf\nComparing models on dataset: lemmatized_count\nComparing models on dataset: lemmatized_word2vec\nComparing models on dataset: lemmatized_doc2vec\nComparing models on dataset: stemmed_tfidf\nComparing models on dataset: stemmed_count\nComparing models on dataset: stemmed_word2vec\nComparing models on dataset: stemmed_doc2vec\n\nResults for original_tfidf:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.81      0.79      0.80       779\n             Bipolar       0.88      0.75      0.81       580\n          Depression       0.74      0.73      0.74      3100\n              Normal       0.83      0.95      0.88      3327\nPersonality disorder       0.85      0.54      0.66       248\n              Stress       0.68      0.54      0.60       557\n            Suicidal       0.68      0.63      0.66      2018\n\n            accuracy                           0.77     10609\n           macro avg       0.78      0.70      0.74     10609\n        weighted avg       0.77      0.77      0.77     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.76      0.78      0.77       779\n             Bipolar       0.80      0.73      0.76       580\n          Depression       0.72      0.67      0.69      3100\n              Normal       0.86      0.91      0.88      3327\nPersonality disorder       0.68      0.56      0.62       248\n              Stress       0.59      0.53      0.56       557\n            Suicidal       0.61      0.65      0.63      2018\n\n            accuracy                           0.74     10609\n           macro avg       0.72      0.69      0.70     10609\n        weighted avg       0.74      0.74      0.74     10609\n\n\nResults for original_count:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.80      0.77      0.79       779\n             Bipolar       0.89      0.75      0.81       580\n          Depression       0.75      0.72      0.73      3100\n              Normal       0.81      0.95      0.88      3327\nPersonality disorder       0.83      0.53      0.65       248\n              Stress       0.69      0.54      0.60       557\n            Suicidal       0.68      0.63      0.66      2018\n\n            accuracy                           0.77     10609\n           macro avg       0.78      0.70      0.73     10609\n        weighted avg       0.77      0.77      0.76     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.76      0.76      0.76       779\n             Bipolar       0.82      0.73      0.77       580\n          Depression       0.71      0.68      0.70      3100\n              Normal       0.87      0.92      0.89      3327\nPersonality disorder       0.71      0.57      0.63       248\n              Stress       0.59      0.54      0.56       557\n            Suicidal       0.59      0.61      0.60      2018\n\n            accuracy                           0.74     10609\n           macro avg       0.72      0.69      0.70     10609\n        weighted avg       0.74      0.74      0.74     10609\n\n\nResults for original_word2vec:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.76      0.66      0.71       779\n             Bipolar       0.72      0.57      0.63       580\n          Depression       0.65      0.72      0.69      3100\n              Normal       0.84      0.92      0.88      3327\nPersonality disorder       0.78      0.38      0.51       248\n              Stress       0.64      0.41      0.50       557\n            Suicidal       0.62      0.59      0.60      2018\n\n            accuracy                           0.72     10609\n           macro avg       0.72      0.61      0.65     10609\n        weighted avg       0.72      0.72      0.72     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.66      0.71      0.69       779\n             Bipolar       0.63      0.61      0.62       580\n          Depression       0.68      0.66      0.67      3100\n              Normal       0.84      0.89      0.87      3327\nPersonality disorder       0.49      0.36      0.41       248\n              Stress       0.52      0.43      0.47       557\n            Suicidal       0.60      0.61      0.61      2018\n\n            accuracy                           0.71     10609\n           macro avg       0.63      0.61      0.62     10609\n        weighted avg       0.70      0.71      0.70     10609\n\n\nResults for original_doc2vec:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.75      0.57      0.64       779\n             Bipolar       0.67      0.45      0.54       580\n          Depression       0.59      0.69      0.63      3100\n              Normal       0.80      0.91      0.85      3327\nPersonality disorder       0.61      0.29      0.39       248\n              Stress       0.54      0.32      0.40       557\n            Suicidal       0.57      0.51      0.54      2018\n\n            accuracy                           0.67     10609\n           macro avg       0.64      0.53      0.57     10609\n        weighted avg       0.67      0.67      0.66     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.64      0.60      0.62       779\n             Bipolar       0.54      0.50      0.52       580\n          Depression       0.63      0.59      0.61      3100\n              Normal       0.79      0.91      0.85      3327\nPersonality disorder       0.37      0.32      0.34       248\n              Stress       0.43      0.37      0.40       557\n            Suicidal       0.53      0.50      0.52      2018\n\n            accuracy                           0.65     10609\n           macro avg       0.56      0.54      0.55     10609\n        weighted avg       0.64      0.65      0.65     10609\n\n\nResults for lemmatized_tfidf:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.81      0.78      0.79       779\n             Bipolar       0.88      0.74      0.81       580\n          Depression       0.74      0.73      0.73      3100\n              Normal       0.82      0.95      0.88      3327\nPersonality disorder       0.87      0.55      0.67       248\n              Stress       0.68      0.52      0.59       557\n            Suicidal       0.68      0.64      0.66      2018\n\n            accuracy                           0.77     10609\n           macro avg       0.78      0.70      0.73     10609\n        weighted avg       0.77      0.77      0.77     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.74      0.79      0.77       779\n             Bipolar       0.82      0.75      0.78       580\n          Depression       0.71      0.69      0.70      3100\n              Normal       0.85      0.91      0.88      3327\nPersonality disorder       0.68      0.56      0.62       248\n              Stress       0.62      0.51      0.56       557\n            Suicidal       0.62      0.62      0.62      2018\n\n            accuracy                           0.74     10609\n           macro avg       0.72      0.69      0.70     10609\n        weighted avg       0.74      0.74      0.74     10609\n\n\nResults for lemmatized_count:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.80      0.78      0.79       779\n             Bipolar       0.89      0.77      0.82       580\n          Depression       0.75      0.72      0.73      3100\n              Normal       0.82      0.95      0.88      3327\nPersonality disorder       0.83      0.56      0.67       248\n              Stress       0.69      0.52      0.59       557\n            Suicidal       0.68      0.64      0.66      2018\n\n            accuracy                           0.77     10609\n           macro avg       0.78      0.71      0.74     10609\n        weighted avg       0.77      0.77      0.77     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.78      0.76      0.77       779\n             Bipolar       0.78      0.76      0.77       580\n          Depression       0.70      0.68      0.69      3100\n              Normal       0.87      0.91      0.89      3327\nPersonality disorder       0.70      0.59      0.64       248\n              Stress       0.59      0.54      0.56       557\n            Suicidal       0.60      0.62      0.61      2018\n\n            accuracy                           0.74     10609\n           macro avg       0.72      0.69      0.71     10609\n        weighted avg       0.74      0.74      0.74     10609\n\n\nResults for lemmatized_word2vec:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.72      0.66      0.69       779\n             Bipolar       0.73      0.56      0.63       580\n          Depression       0.64      0.70      0.67      3100\n              Normal       0.83      0.92      0.88      3327\nPersonality disorder       0.76      0.39      0.51       248\n              Stress       0.64      0.37      0.47       557\n            Suicidal       0.62      0.60      0.61      2018\n\n            accuracy                           0.71     10609\n           macro avg       0.71      0.60      0.64     10609\n        weighted avg       0.71      0.71      0.71     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.75      0.64      0.69       779\n             Bipolar       0.65      0.56      0.60       580\n          Depression       0.63      0.75      0.68      3100\n              Normal       0.87      0.88      0.87      3327\nPersonality disorder       0.44      0.35      0.39       248\n              Stress       0.59      0.39      0.47       557\n            Suicidal       0.61      0.55      0.58      2018\n\n            accuracy                           0.70     10609\n           macro avg       0.65      0.59      0.61     10609\n        weighted avg       0.70      0.70      0.70     10609\n\n\nResults for lemmatized_doc2vec:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.70      0.55      0.62       779\n             Bipolar       0.71      0.43      0.54       580\n          Depression       0.59      0.68      0.63      3100\n              Normal       0.80      0.91      0.85      3327\nPersonality disorder       0.57      0.26      0.36       248\n              Stress       0.52      0.34      0.41       557\n            Suicidal       0.58      0.51      0.54      2018\n\n            accuracy                           0.67     10609\n           macro avg       0.64      0.53      0.56     10609\n        weighted avg       0.67      0.67      0.66     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.62      0.59      0.61       779\n             Bipolar       0.52      0.54      0.53       580\n          Depression       0.63      0.57      0.60      3100\n              Normal       0.81      0.90      0.85      3327\nPersonality disorder       0.44      0.36      0.39       248\n              Stress       0.39      0.35      0.37       557\n            Suicidal       0.54      0.54      0.54      2018\n\n            accuracy                           0.65     10609\n           macro avg       0.56      0.55      0.56     10609\n        weighted avg       0.64      0.65      0.65     10609\n\n\nResults for stemmed_tfidf:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.82      0.80      0.81       779\n             Bipolar       0.90      0.74      0.81       580\n          Depression       0.74      0.73      0.73      3100\n              Normal       0.83      0.95      0.89      3327\nPersonality disorder       0.85      0.56      0.68       248\n              Stress       0.70      0.56      0.62       557\n            Suicidal       0.67      0.64      0.66      2018\n\n            accuracy                           0.77     10609\n           macro avg       0.79      0.71      0.74     10609\n        weighted avg       0.77      0.77      0.77     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.78      0.76      0.77       779\n             Bipolar       0.80      0.71      0.75       580\n          Depression       0.70      0.68      0.69      3100\n              Normal       0.86      0.91      0.89      3327\nPersonality disorder       0.65      0.56      0.61       248\n              Stress       0.61      0.53      0.56       557\n            Suicidal       0.60      0.64      0.62      2018\n\n            accuracy                           0.74     10609\n           macro avg       0.71      0.68      0.70     10609\n        weighted avg       0.74      0.74      0.74     10609\n\n\nResults for stemmed_count:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.80      0.79      0.80       779\n             Bipolar       0.87      0.75      0.80       580\n          Depression       0.75      0.71      0.73      3100\n              Normal       0.83      0.95      0.88      3327\nPersonality disorder       0.85      0.55      0.67       248\n              Stress       0.69      0.54      0.61       557\n            Suicidal       0.68      0.66      0.67      2018\n\n            accuracy                           0.77     10609\n           macro avg       0.78      0.71      0.74     10609\n        weighted avg       0.77      0.77      0.77     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.77      0.77      0.77       779\n             Bipolar       0.83      0.73      0.78       580\n          Depression       0.69      0.67      0.68      3100\n              Normal       0.87      0.92      0.89      3327\nPersonality disorder       0.67      0.56      0.61       248\n              Stress       0.61      0.54      0.57       557\n            Suicidal       0.59      0.62      0.60      2018\n\n            accuracy                           0.74     10609\n           macro avg       0.72      0.69      0.70     10609\n        weighted avg       0.74      0.74      0.74     10609\n\n\nResults for stemmed_word2vec:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.77      0.69      0.73       779\n             Bipolar       0.73      0.58      0.65       580\n          Depression       0.64      0.70      0.67      3100\n              Normal       0.84      0.92      0.88      3327\nPersonality disorder       0.76      0.35      0.48       248\n              Stress       0.69      0.44      0.54       557\n            Suicidal       0.62      0.59      0.61      2018\n\n            accuracy                           0.72     10609\n           macro avg       0.72      0.61      0.65     10609\n        weighted avg       0.72      0.72      0.71     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.65      0.76      0.70       779\n             Bipolar       0.72      0.54      0.62       580\n          Depression       0.66      0.69      0.67      3100\n              Normal       0.86      0.88      0.87      3327\nPersonality disorder       0.53      0.36      0.43       248\n              Stress       0.52      0.41      0.46       557\n            Suicidal       0.60      0.59      0.60      2018\n\n            accuracy                           0.71     10609\n           macro avg       0.65      0.60      0.62     10609\n        weighted avg       0.70      0.71      0.70     10609\n\n\nResults for stemmed_doc2vec:\nXGBoost Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.70      0.57      0.63       779\n             Bipolar       0.70      0.46      0.55       580\n          Depression       0.59      0.69      0.64      3100\n              Normal       0.80      0.91      0.85      3327\nPersonality disorder       0.62      0.29      0.40       248\n              Stress       0.54      0.30      0.39       557\n            Suicidal       0.59      0.52      0.55      2018\n\n            accuracy                           0.68     10609\n           macro avg       0.65      0.54      0.57     10609\n        weighted avg       0.67      0.68      0.67     10609\n\nMLP Classification Report:\n                      precision    recall  f1-score   support\n\n             Anxiety       0.66      0.63      0.65       779\n             Bipolar       0.57      0.51      0.54       580\n          Depression       0.62      0.60      0.61      3100\n              Normal       0.79      0.91      0.84      3327\nPersonality disorder       0.38      0.33      0.36       248\n              Stress       0.41      0.36      0.39       557\n            Suicidal       0.57      0.50      0.54      2018\n\n            accuracy                           0.66     10609\n           macro avg       0.57      0.55      0.56     10609\n        weighted avg       0.65      0.66      0.65     10609\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Best Performing Dataset\nXGBoost Classifier:\n\nThe original_tfidf and original_count datasets both achieved the highest accuracy of 77% and have strong F1-scores across most classes.\n\nThe lematized_tfidf and lematized_count datasets also achieved 77% accuracy, but with lower F1-scores for some classes.\n\nMLP Classifier:\n\nThe original_tfidf and original_count datasets achieved the highest accuracy of 74%.\n\nThe lemmatized_tfidf and lemmatized_count datasets showed similar performance with 74% accuracy.","metadata":{}}]}